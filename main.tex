\documentclass{sig-alternate-05-2015}
\begin{document}

\setcopyright{acmcopyright}

\title{Improving Collaborative Filtering with Embedding Model}

\numberofauthors{1}
\author{
\alignauthor
Chao Lv \quad
Lili Yao \quad
Yansong Feng \quad
Dongyan Zhao\titlenote{Corresponding author.}\\
\affaddr{Institute of Computer Science and Technology}\\
\affaddr{Peking University, Beijing 100871, China}\\
\email{\{lvchao, yaolili, fengyansong, zhaodongyan\}@pku.edu.cn}
}

\maketitle

\begin{abstract}
Collaborative filtering (CF) has been widely employed within recommender systems in many real-world situations.
Learning effective latent factors plays the most important role in collaborative filtering.
Traditional CF methods based upon matrix factorization techniques learn the latent factors from the user-item ratings and suffer from the cold start problem as well as the sparsity problem.
Some improved CF methods enrich the priors on the latent factors by incorporating side information as regularization.
However, the learned latent factors may not be very effective due to the sparse nature of the ratings and the side information.
To tackle this problem, we learn effective latent representations via deep learning.
Deep learning models have emerged as very appealing in learning effective representations in many applications.
In particular, we propose a general deep architecture for CF by integrating matrix factorization with deep feature learning.
We provide a natural instantiations of our architecture by combining probabilistic matrix factorization with marginalized denoising stacked auto-encoders.
The combined framework leads to a parsimonious fit over the latent features as indicated by its improved performance in comparison to prior state-of-art models over four large datasets for the tasks of movie/book recommendation and response prediction.
\end{abstract}

\category{H.2.8}{Database Management}{Data Mining}
\category{H.3.3}{Information Search and Retrieval}{Information Filtering}
\terms{Algorithms, Experimentation, Performance}
\keywords{Collaborative Filtering; Embedding}

\section{Introduction}
Recommender system has become more and more popular in many real-world situations, in the modern era of information overload.
Lots of websites (e.g. Amazon, Netflix, Alibaba and Hulu) use recommender system to target customers and provide them with useful information.
Recommender system aims to help users find the items, they are more likely to be interested in, from huge amounts of candidates.
A widely used setting of recommendation system is to predict how a user would rate an item (such as a movie) given the past rating history of the users.
Many classical recommendation methods have been proposed in recent years and they can be categorized into three classes:
content-based methods, collaborative filtering (CF) based methods, and hybrid methods.
Content-based methods \cite{pazzani2007content} make use of user profiles or product descriptions for recommendation.
CF-based methods \cite{su2009survey} use the past activities or preferences, such as user ratings on items, without using user or product content information.
Hybrid methods \cite{wang2011collaborative} seek to get the best of both worlds by combining content-based and CF-based methods.
The CF based methods have been developed for many years and keep to be a hot area in both academia and industry due to their impressive performance.
Collaborative filtering focuses on predicting the preference of one user by combining his feedback on a few items and the feedback of all other users.
Among various CF based methods, matrix factorization (MF) models have become popular and achieves the state-of-the-art performance \cite{koren2009matrix}.

\section{Relate Work}
\subsection{Matrix Factoriztion}
\subsection{Nerual Network}

\section{Method}
This is the abstract about the paper this is the abstract about the paper.

\subsection{SubMethod}
This is the abstract about the paper this is the abstract about the paper.
This is the abstract about the paper this is the abstract about the paper.
This is the abstract about the paper this is the abstract about the paper.
This is the abstract about the paper this is the abstract about the paper.

\subsection{SubMethod}
This is the abstract about the paper this is the abstract about the paper.
This is the abstract about the paper this is the abstract about the paper.
This is the abstract about the paper this is the abstract about the paper.
This is the abstract about the paper this is the abstract about the paper.

\section{Experiment}
In this section, we conduct several experiments to evaluate the effectiveness of our embedding model.
In these experiments, we also conduct corresponding analysis to investigate:
(1) the influence of the various feedback entity model parameter settings on
retrieval performance;
(2) the effects of feedback tweets number;
(3) the influence of the interpolation coefficient in query expansion and
(4) a comparison of two different entity feedback acquisition methods.



\begin{table*}[htpb]
	\centering
	\caption{Statistics of datasets used in our experiment.}
	\label{tab:topics}
	\begin{tabular}{|l|c|c|c|c|c|c|}
		\hline
		\textbf{Dataset} & \textbf{\#Users} & \textbf{\#Items} & \textbf{\#Ratings} & \textbf{Sparsity} & \textbf{User Features} & \textbf{Item Features} \\
		\hline
		MovieLens-1m  & 6,040   & 3,706  & 1,000,209  & 95.53\% & Gender, Age, and occupation & Genres \\
		MovieLens-10m & 69,878  & 10,677 & 10,000,054 & 98.66\% & - & Genres \\
		MovieLens-20m & 138,493 & 26,744 & 20,000,263 & 99.46\% & - & Genres \\
		\hline
	\end{tabular}
\end{table*}



We employ the root mean squared error (RMSE) and mean absolute error (MAE) as the evaluation metric.
RMSE and MAE are defined as:
$$ RSME = \sqrt{ \frac{1}{N} \sum_{i,j} I_{ij} (R_{ij} - \hat{R}_{ij})^2 } $$
$$ MAE = \frac{1}{N} \sum_{i,j} I_{ij} |R_{ij} - \hat{R}_{ij}| $$
where $N$ is the total number of ratings in the test set,
$R_{ij}$ is the ground-truth rating of user $i$ for item $j$,
$\hat{R_{ij}}$ denotes the corresponding predicted rating,
and $I_{ij}$ is abinary matrix that indicates the ratings in the test set.



\subsection{Movie Recommendation}
For movie recommendation, we conduct experiments on two benchmark
datasets MovieLens-100K and MovieLens-1M 1, which are
commonly used for evaluating collaborative filtering algorithms.
The MovieLens-100K dataset contains 100K ratings of 943 users
and 1682 movies, and the MovieLens-1M dataset consists of about
1 million ratings of 6040 users and 3706 movies. Each rating is
an integer between 1 (worst) and 5 (best). The ratings are highly
sparse. Table 2 summarizes the statistics of datasets. We extract
the features from side information of users and movies to construct
X and Y . To summarize, the user information which consists of
the userâ€˜s age, gender and occupation were encoded into a binary
valued vector of length 28. Similarly, the item feature information
which consists of the 18 category of movie genre were encoded into
a binary valued vector of length 18. Ratings were normalized to be
zero-mean.

\section{Conclusions}
This is the abstract about the paper this is the abstract about the paper.
This is the abstract about the paper this is the abstract about the paper.
This is the abstract about the paper this is the abstract about the paper.
This is the abstract about the paper this is the abstract about the paper.

\section{Acknowledgments}
The work reported in this paper is supported by the National Natural Science Foundation of China Grant 61370116.
We thank anonymous reviewers for their beneficial comments.
We also thank Feifan Fan and Yue Fei for valuable suggestions related to this paper.

\bibliographystyle{abbrv}
\bibliography{sigproc}

\end{document}
