\documentclass{sig-alternate-05-2015}
\usepackage{amsmath}
\usepackage{amssymb}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\usepackage{mathrsfs}

\begin{document}

\setcopyright{acmcopyright}

\title{Improving Collaborative Filtering with Latent Side Information}

\numberofauthors{1}
\author{
\alignauthor
Chao Lv \quad
Lili Yao \quad
Yansong Feng \quad
Dongyan Zhao\titlenote{Corresponding author.}\\
\affaddr{Institute of Computer Science and Technology}\\
\affaddr{Peking University, Beijing 100871, China}\\
\email{\{lvchao, yaolili, fengyansong, zhaodongyan\}@pku.edu.cn}
}

\maketitle

\begin{abstract}
Collaborative filtering (CF) has been widely employed within recommender systems in many real-world situations.
Its basic assumption is that items liked by the same user would be similar or users like same items would share similar interest.
But it not always holds because users' interest may change over time.
If user likes two items at the same time period, there is a strong possibility that they are similar.
But the possibility will become small if user likes they at different time point.
In this paper, we propose a method that takes advantage of user ratings timeline to describe the time sensitive relationship between users and items.
To reach this goal, we use a language-based algorithm to learn effective latent embeddings for users and items.
Language model aims to extract the potential association between sentences and words, which is similar with users and items in recommender system.
The learned embedding for users and items can be considered as a kind of side information that describes the time sensitive relationship between users and items.
We then combine them with origin rating information to predict missing ratings in a feature-based collaborative filtering framework.
Experimental results on three MovieLens datasets demonstrate that our approach can achieve the state-of-the-art performance.
\end{abstract}

\category{H.2.8}{Database Management}{Data Mining}
\category{H.3.3}{Information Search and Retrieval}{Information Filtering}
\terms{Algorithms, Experimentation, Performance}
\keywords{Recommender System; Collaborative Filtering; Embedding Model;}

\section{Introduction}
Recommender system has become more and more popular in many real-world situations, in the modern era of information overload.
Lots of websites (e.g. Amazon, Netflix, Alibaba and Hulu) use recommender system to target customers and provide them with useful information.
Recommender system aims to help users find the items, they are more likely to be interested in, from huge amounts of candidates.
A widely used setting of recommendation system is to predict how a user would rate an item (such as a movie) given the past rating history of the users.
Many classical recommendation methods have been proposed in recent years and they can be categorized into three classes:
content-based methods, collaborative filtering (CF) based methods, and hybrid methods.
Content-based methods \cite{pazzani2007content} make use of user profiles or product descriptions for recommendation.
CF-based methods \cite{su2009survey} use the past activities or preferences, such as user ratings on items, without using user or product content information.
Hybrid methods \cite{wang2011collaborative} seek to get the best of both worlds by combining content-based and CF-based methods.
The CF based methods have been developed for many years and keep to be a hot area in both academia and industry due to their impressive performance.
Collaborative filtering focuses on predicting the preference of one user by combining his feedback on a few items and the feedback of all other users.
Among various CF based methods, matrix factorization (MF) models have become popular and achieves the state-of-the-art performance \cite{koren2009matrix}.

\section{Relate Work}
\subsection{Matrix Factoriztion}
The importance of accurate recommendation techniques motivated by wide ranging applications
has fuelled a great amount of academic as well as industrial research in this area \cite{ricci2011introduction}.
Recommender systems are most often based on collaborative filtering and
there are typically two approaches that are widely used.
In neighborhood methods, the similarity between users based on the content
they have consumed and rated is the basis of a new recommendation.
A related but intrinsically more powerful approach has been the use of latent factor models.

Matrix factorization (MF) is the most popular technique to derive latent factor models and
their success at the Netflix competition have highlighted their strength \cite{koren2009matrix, bennett2007netflix}.
For example, the given matrix $x \in \mathbb{R}^{N*M}$ consisting of the item preferences of the users
can be decomposed as a product of two low dimensional matrices $U$ and $V$.
The decomposition can be carried out by a variety of methods ranging from SVD based approaches \cite{mazumder2010spectral}
to the relatively new non-negative matrix factorization approach \cite{lee2001algorithms}.

One classical MF method is probabilistic matrix factorization (PMF) \cite{salakhutdinov2011probabilistic}.
The underlying assumption behind this method is that
the prior probability distribution of the latent factors and
the probability of the observed ratings given the latent factors
follows a Gaussian distribution.
Many algorithms have been developed to enhance the performance of PMF,
by designing the Bayesian versions \cite{salakhutdinov2008bayesian, xu2013fast, shi2013scmf},
or incorporating side information, such as social relationships \cite{zhao2014leveraging, ma2011recommender}.

Although promising, matrix factorization methods suffer from the problem of cold-start,
i.e. what recommendations to make when a new user/item arrives in the system.
Another problem often presented in many real world applications is data sparsity
or reduced coverage.
Incorporating side information has shown promising performance
in collaborative filtering in such scenarios.
Porteous et al. proposed a Bayesian matrix factorization (BMF) approach
with side information and Dirichlet process mixtures \cite{porteous2010bayesian}.
A variational BMF method and a hierarchical BMF method that utilizes
side information were also proposed in \cite{kim2014scalable} and \cite{park2013hierarchical}, respectively.
Hu et al. proposed a cross-domain triadic factorization (CDTF)
method \cite{hu2013personalized}, which leverages the information from other domains.
The methods discussed above are proposed for addressing recommendation
problems.
Recently, MF based collaborative filtering is also applied to response prediction \cite{menon2011response, li2015predicting}.
The afore-mentioned approaches can alleviate the problem of cold start
and data sparsity but might still suffer when the side information is sparse.
Learning effective features is critical in matrix factorization.
Recently, deep learning based methods have emerged as a powerful tool
for learning representation and are widely used in many applications
ranging from computer vision to speech recognition and machine translation.
In this paper, our goal is to combine deep learning based methods with
matrix factorization for collaborative filtering.
In the next subsection, we survey the application of deep learning
based methods for collaborative filtering.

\subsection{Nerual Network}
The application of deep learning models to the task of collaborative filtering
is very new and there are not much attempts in this direction.
Salakhutdinov et al. \cite{salakhutdinov2007restricted} were the first to apply deep learning to the task of collaborative filtering.
They modified the restricted Boltzmann machines as a two-layer undirected graphical model
consisting of binary hidden units and softmax visible units for the task of collaborative filtering.
They designed an efficient learning procedure called the Contrastive Divergence (CD) to
maximize an approximation to the true likelihood function.
They also proposed a conditional RBM model and inference procedures.
They tested the performance of the model on the Netflix dataset for movie recommendation
and showed that their model performs well as compared to the baseline methods.

Truyen et al. \cite{phung2009ordinal} proposed ordinal Boltzmann machines for collaborative filtering.
They studied the parameterizations for handling the ordinal nature of ratings,
and presented the integration of multiple Boltzmann machines for user-based and item-based processes.

Recently, some deep learning models learn latent factors from content information
such as raw features of audio or articles \cite{hu2014deep, ouyang2014autoencoder}.
Wang et al. \cite{wang2014improving} utilized deep belief nets (DBN) for music recommendation,
which unifies feature extraction and recommendation of songs in a joint framework.
They assumed that a user has a feature vector $\beta_u$ drawn from a Gaussian prior
and the songs have a feature vector $x_v$.
They automatically learned the feature vectors of the songs using a deep belief network
which is a generative probabilistic graphical model with hidden nodes and observation.
It has millions of parameters to be learned from the training data.
The authors used stacked layers of Restricted Boltzmann Machines
for pretraining in an unsupervised fashion, and then employed
the Maximum Likelihood Estimation (MLE) for supervised learning.

Oord et al. \cite{van2013deep} addressed the music recommendation problem
using the convolutional neural networks.
They first conducted a weighted matrix factorization to handle implicit feedback
and obtained latent factors for all songs.
After that they used deep learning to map audio content to those latent factors.
In particular, they extracted local features from audio signals and
aggregated them into a bag-of-words representation.
Finally, the deep convolutional network was employed to map this feature representation
to the latent factors.
They tested their algorithm on the Million song dataset and
showed that their model improved the recommendation performance by augmenting the audio signals.

All the previously mentioned approaches mainly modify the deep learning algorithms
for the task of collaborative filtering and
do not directly couple matrix factorization with deep learning models.
Most recently, Wang et al. \cite{wang2015collaborative} proposed a hierarchical Bayesian model
called collaborative deep learning (CDL) which tightly couples
stacked denoising auto-encoders (SDA) and collaborative topic regression (CTR).
This work is the closest to our work but differs from ours in many significant ways as follows -
(i) CDL utilized a Bayesian formulation of SDA.
The generative process of CDL consists of drawing samples for CDL uses an EM-style algorithm
for obtaining the MAP estimates of Bayesian SDA,
and thus it has to learn a large number of parameters.
Our model employs a more efficient architecture, marginalized SDA (mSDA),
which computes the parameters in closed form and is thus highly efficient and scalable.
(ii) CDL only extracts deep features for items,
whereas our model learns deep features for both items and users.

\section{Our Approach}
In this section,
we first describe the definition of the task to be solved and
the notation we are going to use in this paper. 
Then we introduce our embedding model to extract the relationship
between users and items based on the local interest and global interest.
In the last, we utilize the embedding information as pseudo side information
in the machine learning model to do the final prediction.

\subsection{Problem Definition}
Given $N$ users and $M$ items, the rating $r_{ij}$ is the rating given by
the $i^{th}$ user for the $j^{th}$ item.
In the common real-world situations,
users usually rate on a fraction of items, not on the whole items.
Therefore,
those ratings entail a sparse matrix $\mathbf{R} \in \mathbb{R}^{N \times M}$,
as illustrated in Figure \ref{fig:matrix}.
The goal of recommender system is to make a prediction on the missing ratings.
Based on that, we will know the preference of a user on the items he never rates,
and recommend high score items to him.

\begin{figure}[htbp]
	\centering
	% \includegraphics[scale=0.8]{images/3.pdf}
	\includegraphics[scale=0.4]{images/4.png}
	\caption{An Example of Matrix R}
	\label{fig:matrix}
\end{figure}

Matrix Factorization is a classic method to solve this problem.
It aims to find a $K$ dimensional low rank matrix $\mathbf{\hat{R}} \in \mathbb{R}^{N \times M}$
where $\mathbf{\hat{R}} = \mathbf{U} \mathbf{V}^\mathrm{T}$ with
$\mathbf{U} \in \mathbb{R}^{N \times K}$ and $\mathbf{V} \in \mathbb{R}^{M \times K}$
are two matrices of rank $K$ encoding a dense representation of the users and items with

\begin{equation}
\begin{aligned}
	\argmin_{\mathbf{U},\mathbf{V}}
	\sum_{(i,j) \in \mathcal{K}(\mathbf{R})}
	( r_{ij} - \overline{\mathbf{u}}_i^{\mathrm{T}} \overline{\mathbf{v}}_j ) ^ 2 +
	\lambda ( \left\| \overline{\mathbf{u}}_i \right\|_{Fro}^2 +
	\left\| \overline{\mathbf{v}}_j \right\|_{Fro}^2 )
\end{aligned}
\end{equation}

where $\mathcal{K}(\mathbf{R})$ is the set of indices of known ratings,
$\overline{\mathbf{u}}_i$ and $\overline{\mathbf{v}}_j$
are the corresponding line vectors of $\mathbf{U}$ and $\mathbf{V}$,
$\lambda$ is the coefficient that controls the influence of L2 regularization,
and $\left\| \cdot \right\|_{Fro}$ is the Frobenius norm.

Matrix Factorization techniques, as the main thrust behind collaborative filtering,
have been developed for many years and keep to be a hot area in both academia and industry.
But it suffers from the problem of cold-start,
i.e. what recommendations to make when a new user or a new item arrives in the system
with the fact that their have no ratings information.
Meanwhile, when the ratings information is too sparse,
the performance of matrix factorization will decrease rapidly.

Side information, such as the users' profiles and the items' properties,
is a effective resource to remit this problem.
In the next section, we will propose a embedding model
to extract latent side information based on the local interest and global interest.

\subsection{Embedding Model}
Collaborative Filtering aims at estimating the ratings
a user would have given to all other items he never interact with
by using the ratings of all the other users.
The basic assumption of collaborative filtering is that
items liked by the same user would be similar
or users like same items would share similar interest.
However, in real-world situations,
it is not always hold because users' interest may change over
a long time period.
Meanwhile, the interest distribution of a user in a fixed time period
are stable and don't change too much.

To describe the phenomenon that interest changes over time,
we propose the definition of \textbf{local interest} and \textbf{global interest}.

\begin{itemize}
\item \textbf{local interest} reflects the interest distribution of a user
in a short and fixed time period.
\item \textbf{global interest} reflects the interest distribution of a user
in a long time period.
\end{itemize}

And we believe that item in the same local interest (i.e. in the same time period)
of a user have a higher possibility to be similar than
items in different local interest.

\begin{figure*}[htbp]
	\centering
	\includegraphics[scale=0.6]{images/1.pdf}
	\caption{A Example for Local Interest and Global Interest}
	\label{fig:example}
\end{figure*}

For example, as illustrated in the left of Figure \ref{fig:example},
given a certain $\mathbf{user}$, we can see he interact with five items
($\mathbf{item1}$ to $\mathbf{item5}$) in the last.
They are list on the time line according to the time order.
Let's assume that the time window size \footnote{We use time window to judge time proximity
instead of extract timestamp here for convenience.} is set to $2$,
Therefore $\mathbf{item1}$ and $\mathbf{item2}$ are in the same local interest,
$\mathbf{item2}$ and $\mathbf{item3}$ are in the same local interest, and so on.
Meanwhile $\mathbf{item2}$ and $\mathbf{item5}$ are in different local interest.
That means $\mathbf{item2}$ has a higher possibility to be similar with $\mathbf{item1}$
than $\mathbf{item5}$.

To describe the similarity preference in mathematical sense,
we project users and items into a low-dimensionality space,
and change the interest similarity into spacial distance.
$\mathbf{item2}$ is close to $\mathbf{item1}$ and far away from $\mathbf{item5}$
in the low-dimensionality space, as shown in the right of Figure \ref{fig:example}.

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.55]{images/2.pdf}
	\caption{Embedding Model for Extracting Interest Similarity from Users and Items}
	\label{fig:embedding}
\end{figure}

Inspired by paragraph2vec algorithm \cite{le2014distributed} for learning
vector representations of words which take advantage of
a word order observed in a sentence,
we choose to use neural network based language model
to embed this interest similarity information.
The embedding model simultaneously learns vector representations of users and items
by considering the user as a global context,
and the architecture of the embedding model is illustrated in Figure \ref{fig:embedding}.

The training data set was derived from users interaction timeline $T$,
which comprises users $u_i (i=1,2,...,N)$ and their interacted items ordered by the interacted time,
$v_{i_1}$, $v_{i_2}$, ..., $v_{i_{L_i}}$,
where $L_i$ denotes number of items interacted by user $u_i$,
which is much less than the amount of items $M$.

More formally, objective of the embedding model is to
maximize the log-likelihood over the set of $T$ of all the interaction timeline,

\begin{equation}
\begin{aligned}
	\sum_{i=1}^{N} \bigg( &p(u_i | v_{i_1}, v_{i_2}, ..., v_{i_{L_n}}) + \\
	                      &\sum_{j=1}^{L_i} p(v_{i_j} | v_{i_{j-c}}, ..., v_{i_{j-1}}, v_{i_{j+1}},..., v_{i_{j+c}}, u_i) \bigg)
\end{aligned}
\end{equation}

where $c$ is the time window size.
$p(u_i | v_{i_1}, v_{i_2}, ..., v_{i_{L_i}})$ is the probability to generate
the global interest of $u_i$ based on all items he interacted.
The prediction task is typically done via a multiclass classifier,
such as softmax. There, we have

\begin{equation}
	p(u_i | v_{i_1}, v_{i_2}, ..., v_{i_{L_i}}) =
	\frac
	{
		exp ( \overline{\mathbf{v}}_{1}^{\mathrm{T}} \mathbf{v}_{u_i}^{'} )
	}
	{
		\sum_{k=1}^{V} exp ( \overline{\mathbf{v}}_{1}^{\mathrm{T}} \mathbf{v}_{k}^{'} )
	}
\end{equation}

where $\mathbf{v}_{u_i}^{'}$ is the output vector representation of $u_i$,
$V$ is the set of the whole items,
and $\overline{\mathbf{v}}_{1}$ is averaged input vector representation of all the items
interacted by user $u_i$, i.e.

\begin{equation}
	\overline{\mathbf{v}}_{1} = \frac{\sum_{j=1}^{T_i} \mathbf{v}_{v_{i_j}}}{T_i}
\end{equation}

$p(v_{i_j} | v_{i_{j-c}}, ..., v_{i_{j-1}}, v_{i_{j+1}},..., v_{i_{j+c}}, u_i)$
is the probability to generate the interest distribution of $v_{i_j}$
based on items in the same local interest and the user's global interest.
Similarly, using softmax multiclass classifier we have

\begin{equation}
	p(v_{i_j} | v_{i_{j-c}}, ..., v_{i_{j-1}}, v_{i_{j+1}},..., v_{i_{j+c}}, u_i) =
	\frac
	{
		exp( \overline{\mathbf{v}}_{2}^{\mathrm{T}} \mathbf{v}_{v_{i_j}}^{'} )
	}
	{
		\sum_{k=1}^{V} exp( \overline{\mathbf{v}}_{2}^{\mathrm{T}} \mathbf{v}_{k}^{'} )
	}
\end{equation}

where $\mathbf{v}_{v_{i_j}}^{'}$ is the output vector representation of $v_{i_j}$,
$V$ is the set of the whole items,
and $\overline{\mathbf{v}}_{2}$ is averaged input vector representation of items
int the same local interest and corresponding global interest $u_i$.

\begin{equation}
	\overline{\mathbf{v}}_{2} = \frac{ \mathbf{v}_{v_{i_{j-c}}} + ... + \mathbf{v}_{v_{i_{j-1}}} + 
	\mathbf{v}_{v_{i_{j+1}}} + ... + \mathbf{v}_{v_{i_{j+c}}} + \mathbf{v}_{u_i} }{2c+1}
\end{equation}


\subsection{Learning Model}
With the help of embedding model, we can obtain
the vector representation of users and items
based on the local interest and global interest.
We use the following notations to describe these representations:

\begin{itemize}
	\item $\tilde{\mathbf{u}}_i$ reflects the interest distribution of the $u_i$
	\item $\tilde{\mathbf{v}}_j$ reflects the interest distribution of the $v_j$
	\item $D$ is the length of those representation
\end{itemize}

There are two kinds of side information in collaborative filtering:
users' profiles and items' properties.
Various kinds of information can be used to model these factors.
In some sense, the representation of users and items from the embedding model
could be treat as a kind of side information,
because it distinguish the similarity and difference between users and items,
just like other side information does.
But it doesn't reflect a actual meaning, so we call it the \textbf{latent side information}. 

Inspired by svdfeature algorithm \cite{chen2012svdfeature}, we utilize the feature-based
collaborative filtering to take advantage of the latent side information.
First, we generate the user feature $\alpha_{i}$ and the item feature $\beta_{j}$
for user $u_i$ and item $v_j$.

\begin{equation}
\alpha_{i} = \{ OneHot(u_i), \tilde{\mathbf{u}}_i \}
\end{equation}
\begin{equation}
\beta_{j} = \{OneHot(v_j), \tilde{\mathbf{v}}_j \}
\end{equation}

where $OneHot(u_i)$ is the one hot representation of $u_i$
and $OneHot(v_j)$ is the one hot representation of $v_j$.

Then we predict the rating for $u_i$ and $v_j$

\begin{equation}
\hat{r} = \sum_{i=1}^{n} \alpha_{i} b_{i}^{(u)} + \sum_{i=1}^{m} \alpha_{i} b_{i}^{(i)} +
\left( \sum_{i=1}^{n} \alpha_{i} \textbf{p}_{i} \right) ^ \mathrm{T}
\left( \sum_{i=1}^{m} \beta_{i} \textbf{q}_{i} \right)
\end{equation}

where $\textbf{p}_{i} \in \mathbb{R}^d$ and $\textbf{q}_{i} \in \mathbb{R}^d$
are $d$ dimensional latent factors associated with each feature.
$b_{i}^{(u)}$ and $b_{i}^{(i)}$ are bias parameters that directly influence the prediction.


\section{Experiment}

\subsection{Benchmark Models}
libmf \cite{chin2015fast}

libfm \cite{rendle2012factorization}

\subsection{Dataset}
We conduct experiments on three benchmark datasets MovieLens-1M, MovieLens-10M and MovieLens-20M
\footnote{http://grouplens.org/datasets/movielens/},
which are commonly used for evaluating collaborative filtering algorithms.
The MovieLens-1M dataset consists of about 1 million ratings of 6040 users and 3706 movies,
and each rating is an integer between 1 (worst) and 5 (best).
The MovieLens-10M dataset consisits of about 10 million ratings of 69878 users and 10677 movies,
the MovieLens-20M dataset consisits of about 20 million ratings of 138493 users and 26744 movies,
and each rating ranges from 0.5 (worst) to 5.0 (best) step by 0.5.
The ratings are highly sparse.
Table \ref{tab:statistics} summarizes the statistics of three datasets.

\begin{table}[htpb]
	\centering
	\caption{Statistics of three datasets}
	\label{tab:statistics}
	\begin{tabular}{|l|c|c|c|c|}
		\hline
		\textbf{Dataset} & \textbf{\#Users} & \textbf{\#Items} & \textbf{\#Ratings} & \textbf{Sparsity} \\
		\hline
		ML-1M  & 6,040   & 3,706  & 1,000,209  & 95.53\% \\
		ML-10M & 69,878  & 10,677 & 10,000,054 & 98.66\% \\
		ML-20M & 138,493 & 26,744 & 20,000,263 & 99.46\% \\
		\hline
	\end{tabular}
\end{table}

\subsection{Metrics}
We employ the root mean squared error (RMSE) and mean absolute error (MAE) as the evaluation metric.
RMSE and MAE are defined as:
\begin{equation}
	RSME = \sqrt{ \frac{1}{N} \sum_{i,j} I_{ij} (R_{ij} - \hat{R}_{ij})^2 }
\end{equation}
\begin{equation}
	MAE = \frac{1}{N} \sum_{i,j} I_{ij} |R_{ij} - \hat{R}_{ij}|
\end{equation}
where $N$ is the total number of ratings in the test set,
$R_{ij}$ is the ground-truth rating of user $i$ for item $j$,
$\hat{R_{ij}}$ denotes the corresponding predicted rating,
and $I_{ij}$ is abinary matrix that indicates the ratings in the test set.




\section{Conclusions}
This is the abstract about the paper this is the abstract about the paper.
This is the abstract about the paper this is the abstract about the paper.
This is the abstract about the paper this is the abstract about the paper.
This is the abstract about the paper this is the abstract about the paper.

\section{Acknowledgments}
The work reported in this paper is supported by the National Natural Science Foundation of China Grant 61370116.
We thank anonymous reviewers for their beneficial comments.
We also thank Feifan Fan and Yue Fei for valuable suggestions related to this paper.

\bibliographystyle{abbrv}
\bibliography{sigproc}

\end{document}
